{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # thư viện tính toán số học\n",
    "import pandas as pd # thư viện giúp đọc file và xử lí dữ liệu dạng bảng\n",
    "import yfinance as yf # thư viện lấy dữ liệu\n",
    "import tensorflow as tf # thư viện model\n",
    "from tensorflow.keras.models import Sequential # Sắp xếp các lớp\n",
    "from tensorflow.keras.layers import Layer, LSTM, Dense, Dropout # Các lớp sử dụng trong mô hình\n",
    "from sklearn.preprocessing import MinMaxScaler # Chuẩn hóa dữ liệu\n",
    "from sklearn.metrics import mean_squared_error # Tính độ lỗi\n",
    "import matplotlib.pyplot as plt # Thư viện vẽ đồ thị\n",
    "import random # random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b777e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải dữ liệu 10 năm dùng thư viện yfinance\n",
    "def download_stock_data(ticker):\n",
    "    data = yf.download(ticker, period=\"10y\", interval=\"1d\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07dbc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ví dụ về 1 mã cổ phiếu\n",
    "data = download_stock_data(\"GOOG\")\n",
    "# Đảm bảo dữ liệu là của các ngày liên tục ('D': daily),\n",
    "# các ngày không có dữ liệu (T7,CN) thì giá trị dữ liệu được gán NaN\n",
    "data = data.asfreq('D')\n",
    "\n",
    "# Kiểm tra 10 dòng đầu để đảm bảo không sót ngày nào\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07443b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna() là hàm dùng để ghi đè các ô có giá trị NaN\n",
    "# method='ffill' (forward fill) nghĩa là: Nếu một ô có giá trị NaN,\n",
    "# hãy lấy giá trị ở dòng phía trên nó để điền vào ()\n",
    "data = data.fillna(method='ffill')\n",
    "\n",
    "# Kiểm tra 10 dòng đầu để đảm bảo không còn giá trị NaN nào.\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4160ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy ra duy nhất cột giá đóng cửa (Close) –\n",
    "# đây là dữ liệu quan trọng nhất trong phân tích tài chính và dự báo.\n",
    "close_prices = data[['Close']]\n",
    "\n",
    "# Kiểm tra 10 giá trị đầu của chuỗi Close, để đảm bảo dữ liệu được lọc đúng.\n",
    "close_prices.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4541bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vẽ đồ thị giá thực\n",
    "dates = data.index[:]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dates, close_prices, label='Actual Price')\n",
    "plt.title('Stock Price Actual')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f8b301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def directional_loss(y_true, y_pred):\n",
    "    diff_true = y_true[:, 1:] - y_true[:, :-1]\n",
    "    diff_pred = y_pred[:, 1:] - y_pred[:, :-1]\n",
    "    return tf.reduce_mean(tf.maximum(0.0, -diff_true * diff_pred))  # penalize opposite direction\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    alpha = 0.4\n",
    "    beta = 0.2  # phạt underprediction\n",
    "    gamma = 0.3  # phạt overprediction\n",
    "\n",
    "    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    dir_loss = directional_loss(y_true, y_pred)\n",
    "\n",
    "    under_penalty = tf.reduce_mean(tf.nn.relu(y_true - y_pred))\n",
    "    over_penalty = tf.reduce_mean(tf.nn.relu(y_pred - y_true))\n",
    "\n",
    "    return mse + alpha * dir_loss + beta * under_penalty + gamma * over_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13b99d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.2: Build LSTM model using library\n",
    "def build_model(input_shape, units=50, output_steps=5):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(output_steps))  # Output shape = (batch_size, k)\n",
    "    model.compile(optimizer='adam', loss=combined_loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec6fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "def create_dataset(data, window_size=60, k=5):\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data) - k + 1):  # ensure enough room for k steps\n",
    "        X.append(data[i - window_size:i])\n",
    "        y.append(data[i:i + k].flatten())  # output is a sequence of k steps\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00afb7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy dữ liệu gốc\n",
    "close_prices = data['Close'].values.reshape(-1, 1)\n",
    "total_len = len(close_prices)\n",
    "\n",
    "# Chia theo 80% train, 10% val, 10% test\n",
    "train_end = int(0.8 * total_len)\n",
    "val_end = int(0.9 * total_len)\n",
    "\n",
    "# ⚠️ Giữ lại 90 ngày trước khi chia để đủ cho mọi window_size\n",
    "max_window_size = 180\n",
    "train_raw = close_prices[:train_end]\n",
    "val_raw = close_prices[train_end - max_window_size:val_end]\n",
    "test_raw = close_prices[val_end - max_window_size:]\n",
    "\n",
    "# Chuẩn hóa\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train_raw)\n",
    "val_scaled = scaler.transform(val_raw)\n",
    "test_scaled = scaler.transform(test_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9a73bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Genetic Algorithm for hyperparameter tuning\n",
    "def genetic_algorithm(population_size=20, max_generations=30, mutation_rate=0.1, crossover_rate=0.8, k=5, patience=3, no_improve_count = 0, target_mse=0.002): # Các thông số trong GA\n",
    "    # --------------------------\n",
    "    # 1. Create a random individual\n",
    "    def create_individual():\n",
    "        return {\n",
    "            'window_size': random.randint(30, 180), # Kích thước cửa sổ chọn từ 30 đến 90 ngày (có thể thay đổi)\n",
    "            'units': random.choice([64, 128]) # Số units trên 1 lớp LSTM. Chọn các số này là vì GPU, TPU tính toán hiệu quả hơn với các giá trị unit là bội của 32\n",
    "        }\n",
    "\n",
    "    # --------------------------\n",
    "    # 2. Evaluate fitness (lower MSE is better)\n",
    "    def fitness(ind):\n",
    "        #X_win, y_win = create_dataset(scaled_data, ind['window_size'])\n",
    "        #X_win, y_win = X_win[:-100], y_win[:-100]  # use training data # dùng phần đầu để train\n",
    "        #X_val_gen, y_val_gen = X_win[-100:], y_win[-100:] # dùng 100 dữ liệu cuối để test\n",
    "        #split_index = int(len(X_win) * 0.8) # chia tập train - test là 80 - 20\n",
    "        #X_train_gen, y_train_gen = X_win[:split_index], y_win[:split_index]\n",
    "        #X_val_gen, y_val_gen = X_win[split_index:], y_win[split_index:]\n",
    "\n",
    "        # 1. Chia trước (trên dữ liệu gốc chưa scale)\n",
    "        # close_prices = data['Close'].values.reshape(-1, 1)\n",
    "        # train_size = int(len(close_prices) * 0.8)\n",
    "        # train_prices = close_prices[:train_size]\n",
    "        # val_prices = close_prices[train_size - ind['window_size']:]  # giữ lại `window_size` ngày để đảm bảo tạo được sample\n",
    "\n",
    "        # # 2. Chuẩn hóa riêng từng phần\n",
    "        # scaler = MinMaxScaler()\n",
    "        # train_scaled = scaler.fit_transform(train_prices)\n",
    "        # val_scaled = scaler.transform(val_prices)\n",
    "\n",
    "        # # 3. Tạo dataset\n",
    "        # # Inside fitness()\n",
    "        # X_train_gen, y_train_gen = create_dataset(train_scaled, ind['window_size'], k)\n",
    "        # X_val_gen, y_val_gen = create_dataset(val_scaled, ind['window_size'], k)\n",
    "\n",
    "        # model = build_model((ind['window_size'], 1), units=ind['units'], output_steps=k)\n",
    "        # model.fit(X_train_gen, y_train_gen, epochs=3, batch_size=32, verbose=0)\n",
    "\n",
    "        # preds = model.predict(X_val_gen)\n",
    "        # return mean_squared_error(y_val_gen, preds)\n",
    "\n",
    "        window_size = ind['window_size']\n",
    "        units = ind['units']\n",
    "        # Tạo dataset từ tập đã chia & chuẩn hóa\n",
    "        X_train, y_train = create_dataset(train_scaled, window_size, k)\n",
    "        X_val, y_val = create_dataset(val_scaled, window_size, k)\n",
    "\n",
    "        model = build_model((window_size, 1), units=units, output_steps=k)\n",
    "        model.fit(X_train, y_train, epochs=3, batch_size=32, verbose=0)\n",
    "        preds = model.predict(X_val)\n",
    "\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "        return mse\n",
    "\n",
    "\n",
    "    # --------------------------\n",
    "    # 3. Selection: sort by fitness (elitism: top N)\n",
    "    def selection(population, scores, num_elites=5):\n",
    "        sorted_pop = [x for _, x in sorted(zip(scores, population))]\n",
    "        return sorted_pop[:num_elites] # lấy trước 15 cá thể tốt nhất (fitness thấp nhất)\n",
    "\n",
    "    # --------------------------\n",
    "    # 4. Crossover: combine 2 parents into 1 child\n",
    "    def crossover(parent1, parent2):\n",
    "        if random.random() < crossover_rate: # nếu random ra < tỉ lệ lai ghép thì cho lai.\n",
    "            return {\n",
    "                'window_size': random.choice([parent1['window_size'], parent2['window_size']]),\n",
    "                'units': random.choice([parent1['units'], parent2['units']])\n",
    "            }\n",
    "        else:\n",
    "            # No crossover, just clone one of the parents(nếu ko thì ko làm gì)\n",
    "            return random.choice([parent1, parent2]).copy()\n",
    "\n",
    "    # --------------------------\n",
    "    # 5. Mutation: randomly alter genes\n",
    "    def mutate(ind):\n",
    "        if random.random() < mutation_rate: # random ra nhỏ hơn tỉ lệ đột biến thì cho đột biến\n",
    "            ind['window_size'] = random.randint(30, 180)\n",
    "        if random.random() < mutation_rate:\n",
    "            ind['units'] = random.choice([64, 128])\n",
    "        return ind\n",
    "\n",
    "    # --------------------------\n",
    "    # 6. Replacement: create new generation from elites + offspring\n",
    "    def create_next_generation(elites, population, size, scores):\n",
    "        next_gen = elites[:]\n",
    "        sorted_pop = [x for _, x in sorted(zip(scores, population))]\n",
    "        while len(next_gen) < size:\n",
    "            parent1, parent2 = random.sample(sorted_pop[:10], 2) # chọn 4 cá thể tốt nhất xong chọn 2 bố mẹ. Rồi tiến hành lai ghép, đột biến nếu có.\n",
    "            child = crossover(parent1, parent2) # lai ghép\n",
    "            child = mutate(child) # đột biến\n",
    "            next_gen.append(child) # thêm vào thế hệ sau\n",
    "        return next_gen\n",
    "\n",
    "    # --------------------------\n",
    "    # 7. Repeat over generations\n",
    "    population = [create_individual() for _ in range(population_size)]\n",
    "    best_individual = None\n",
    "    best_score = float('inf')\n",
    "\n",
    "    for gen in range(max_generations):\n",
    "        print(f\"\\n Generation {gen+1}\")\n",
    "        scores = [fitness(ind) for ind in population]\n",
    "        for i, (ind, score) in enumerate(zip(population, scores)):\n",
    "            print(f\"Individual {i+1}: window_size={ind['window_size']}, units={ind['units']}, MSE={score:.6f}\")\n",
    "\n",
    "        elites = selection(population, scores, num_elites=5)\n",
    "        best_elite = elites[0]\n",
    "        best_elite_score = scores[population.index(best_elite)]  # lấy đúng fitness đã tính\n",
    "        print(f\"Best individual of generation {gen+1}: window_size={best_elite['window_size']}, units={best_elite['units']}, MSE={best_elite_score:.6f}\")\n",
    "        # 🔸 Điều kiện dừng sớm\n",
    "     \n",
    "        # Kiểm tra cải thiện\n",
    "        if best_elite_score < best_score:\n",
    "            best_score = best_elite_score\n",
    "            best_individual = best_elite.copy()\n",
    "            no_improve_count = 0  # reset bộ đếm\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "            print(f\"No improvement for {no_improve_count} generation(s)\")\n",
    "\n",
    "        # 🔴 DỪNG SỚM nếu không cải thiện trong `patience` thế hệ\n",
    "        if no_improve_count >= patience:\n",
    "            print(f\"\\nEarly stopping: No improvement in the last {patience} generations.\")\n",
    "            break\n",
    "                # 🔴 Dừng sớm nếu đạt MSE mục tiêu\n",
    "        if best_elite_score <= target_mse:\n",
    "            print(f\"\\n✅ Early stopping: Reached target MSE ≤ {target_mse}\")\n",
    "            break\n",
    "\n",
    "\n",
    "        population = create_next_generation(elites, population, population_size, scores) # tạo thế hệ mới (gồm 5 cá thể tốt nhất của thế hệ trước và những cá thể khác được lai ghép, đột biến)\n",
    "\n",
    "    print(f\"\\n Final best individual: window_size={best_individual['window_size']}, units={best_individual['units']}, MSE={best_score:.6f}\")\n",
    "    return best_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0549fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GA optimization\n",
    "best_params = genetic_algorithm(k=5)\n",
    "print(\"Best Parameters from GA:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6794a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 1. Lấy dữ liệu gốc (chưa chuẩn hóa)\n",
    "close_prices = data['Close'].values.reshape(-1, 1)\n",
    "\n",
    "# 2. Chia dữ liệu theo tỉ lệ 80% train, 10% val, 10% test\n",
    "total_len = len(close_prices)\n",
    "train_end = int(total_len * 0.8)\n",
    "val_end = int(total_len * 0.9)\n",
    "\n",
    "train_prices = close_prices[:train_end]\n",
    "val_prices = close_prices[train_end - best_params['window_size']:val_end]\n",
    "test_prices = close_prices[val_end - best_params['window_size']:]  # giữ lại window_size ngày\n",
    "\n",
    "# 3. Fit scaler trên tập train và transform cả 3 phần\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train = scaler.fit_transform(train_prices)\n",
    "scaled_val = scaler.transform(val_prices)\n",
    "scaled_test = scaler.transform(test_prices)\n",
    "\n",
    "# 4. Tạo dataset\n",
    "k=5\n",
    "X_train, y_train = create_dataset(scaled_train, best_params['window_size'], k)\n",
    "X_val, y_val = create_dataset(scaled_val, best_params['window_size'], k)\n",
    "X_test, y_test = create_dataset(scaled_test, best_params['window_size'], k)\n",
    "\n",
    "# 5. Gộp train + val để train mô hình cuối cùng\n",
    "X_final_train = np.concatenate([X_train, X_val])\n",
    "y_final_train = np.concatenate([y_train, y_val])\n",
    "\n",
    "# 6. Xây mô hình\n",
    "model = build_model((best_params['window_size'], 1), best_params['units'])\n",
    "\n",
    "# 7. EarlyStopping (monitor trên `loss` vì không có val)\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 8. Huấn luyện trên train + val\n",
    "model.fit(\n",
    "    X_final_train, y_final_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# 9. Dự đoán trên test set và tính RMSE\n",
    "preds = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"✅ Test RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de45cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "val_preds = model.predict(X_val)\n",
    "\n",
    "def plot_all_forecasts(data, scaler, best_params, y_val, val_preds, y_test, test_preds):\n",
    "    window_size = best_params['window_size']\n",
    "    k = y_val.shape[1]\n",
    "\n",
    "    total_len = len(data)\n",
    "    train_end = int(0.8 * total_len)\n",
    "    val_end = int(0.9 * total_len)\n",
    "\n",
    "    # --- 1. Lấy index gốc ---\n",
    "    train_dates = data.index[:train_end]\n",
    "\n",
    "    val_start_index = train_end - window_size\n",
    "    test_start_index = val_end - window_size\n",
    "\n",
    "    # --- 2. Giải scale ---\n",
    "    y_val_rescaled = scaler.inverse_transform(y_val.reshape(-1, 1)).reshape(y_val.shape)\n",
    "    val_preds_rescaled = scaler.inverse_transform(val_preds.reshape(-1, 1)).reshape(val_preds.shape)\n",
    "\n",
    "    y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1)).reshape(y_test.shape)\n",
    "    test_preds_rescaled = scaler.inverse_transform(test_preds.reshape(-1, 1)).reshape(test_preds.shape)\n",
    "\n",
    "    # --- 3. Tạo dict giá thực ---\n",
    "    def get_actual_dict(y_rescaled, start_idx):\n",
    "        actual_dict = defaultdict(list)\n",
    "        for i in range(len(y_rescaled)):\n",
    "            start = start_idx + i + window_size\n",
    "            for j in range(y_rescaled.shape[1]):\n",
    "                date_idx = start + j\n",
    "                if date_idx < len(data):\n",
    "                    date = data.index[date_idx]\n",
    "                    actual_dict[date].append(y_rescaled[i][j])\n",
    "        return actual_dict\n",
    "\n",
    "    actual_val = get_actual_dict(y_val_rescaled, val_start_index)\n",
    "    actual_test = get_actual_dict(y_test_rescaled, test_start_index)\n",
    "\n",
    "    # --- 4. Dự đoán từng bước ---\n",
    "    def get_pred_lines(preds_rescaled, start_idx):\n",
    "        pred_step_dict = [defaultdict(list) for _ in range(k)]\n",
    "        for i in range(len(preds_rescaled)):\n",
    "            start = start_idx + i + window_size\n",
    "            for j in range(k):\n",
    "                date_idx = start + j\n",
    "                if date_idx < len(data):\n",
    "                    date = data.index[date_idx]\n",
    "                    pred_step_dict[j][date].append(preds_rescaled[i][j])\n",
    "        pred_lines = []\n",
    "        for j in range(k):\n",
    "            common_dates = sorted(set(pred_step_dict[j].keys()))\n",
    "            pred_avg = np.array([np.mean(pred_step_dict[j][d]) for d in common_dates])\n",
    "            pred_lines.append((common_dates, pred_avg))\n",
    "        return pred_lines\n",
    "\n",
    "    val_pred_lines = get_pred_lines(val_preds_rescaled, val_start_index)\n",
    "    test_pred_lines = get_pred_lines(test_preds_rescaled, test_start_index)\n",
    "\n",
    "    # --- 5. Plot ---\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    # Train thực tế\n",
    "    plt.plot(train_dates, data['Close'][:train_end], label='Train Actual', color='gray', linewidth=1.5)\n",
    "\n",
    "    # Val thực tế\n",
    "    val_actual_dates = sorted(actual_val.keys())\n",
    "    val_actual_avg = np.array([np.mean(actual_val[d]) for d in val_actual_dates])\n",
    "    plt.plot(val_actual_dates, val_actual_avg, label='Val Actual', color='blue', linewidth=2)\n",
    "\n",
    "    # Test thực tế\n",
    "    test_actual_dates = sorted(actual_test.keys())\n",
    "    test_actual_avg = np.array([np.mean(actual_test[d]) for d in test_actual_dates])\n",
    "    plt.plot(test_actual_dates, test_actual_avg, label='Test Actual', color='black', linewidth=2)\n",
    "\n",
    "    # Các bước dự đoán val\n",
    "    colors = plt.cm.Blues(np.linspace(0.4, 0.9, k))\n",
    "    for j, (dates, preds_j) in enumerate(val_pred_lines):\n",
    "        plt.plot(dates, preds_j, label=f'Val Predicted t+{j+1}', color=colors[j], linestyle='--')\n",
    "\n",
    "    # Các bước dự đoán test\n",
    "    colors = plt.cm.Greens(np.linspace(0.4, 0.9, k))\n",
    "    for j, (dates, preds_j) in enumerate(test_pred_lines):\n",
    "        plt.plot(dates, preds_j, label=f'Test Predicted t+{j+1}', color=colors[j], linestyle='--')\n",
    "\n",
    "    plt.title(f'Stock Forecasting: Actual vs {k}-step Predictions')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_all_forecasts(data, scaler, best_params, y_val, val_preds, y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282f9915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập validation\n",
    "val_preds = model.predict(X_val)\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Rescale val ground truth và dự đoán\n",
    "y_val_2d = y_val.reshape(-1, 1)\n",
    "val_preds_2d = val_preds.reshape(-1, 1)\n",
    "\n",
    "y_val_rescaled = scaler.inverse_transform(y_val_2d).reshape(y_val.shape)\n",
    "val_preds_rescaled = scaler.inverse_transform(val_preds_2d).reshape(val_preds.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Tạo actual_dict từ y_val_rescaled\n",
    "actual_dict = defaultdict(list)\n",
    "val_start_index = len(data) - len(y_test) - len(y_val) - best_params['window_size']\n",
    "\n",
    "for i in range(len(y_val_rescaled)):\n",
    "    start = val_start_index + i + best_params['window_size']\n",
    "    for j in range(y_val_rescaled.shape[1]):\n",
    "        date_idx = start + j\n",
    "        if date_idx < len(data):\n",
    "            date = data.index[date_idx]\n",
    "            actual_dict[date].append(y_val_rescaled[i][j])\n",
    "\n",
    "actual_dates = sorted(actual_dict.keys())\n",
    "actual_avg = np.array([np.mean(actual_dict[d]) for d in actual_dates])\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Dự đoán từng bước t+1, ..., t+k\n",
    "k = val_preds_rescaled.shape[1]\n",
    "pred_step_dict = [defaultdict(list) for _ in range(k)]\n",
    "\n",
    "for i in range(len(val_preds_rescaled)):\n",
    "    start = val_start_index + i + best_params['window_size']\n",
    "    for j in range(k):\n",
    "        date_idx = start + j\n",
    "        if date_idx < len(data):\n",
    "            date = data.index[date_idx]\n",
    "            pred_step_dict[j][date].append(val_preds_rescaled[i][j])\n",
    "\n",
    "# Trung bình từng bước\n",
    "pred_lines = []\n",
    "step_mae = []\n",
    "for j in range(k):\n",
    "    common_dates = sorted(set(pred_step_dict[j].keys()) & set(actual_dict.keys()))\n",
    "    pred_avg = np.array([np.mean(pred_step_dict[j][d]) for d in common_dates])\n",
    "    actual_avg_step = np.array([np.mean(actual_dict[d]) for d in common_dates])\n",
    "    pred_lines.append((common_dates, pred_avg))\n",
    "    step_mae.append(np.mean(np.abs(pred_avg - actual_avg_step)))\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Đường thực tế\n",
    "plt.plot(actual_dates, actual_avg, label='Actual Price', color='black', linewidth=2)\n",
    "\n",
    "# Các đường dự đoán t+1 đến t+k\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, k))\n",
    "for j in range(k):\n",
    "    dates, preds_j = pred_lines[j]\n",
    "    plt.plot(dates, preds_j, label=f'Predicted t+{j+1}', color=colors[j], alpha=0.7)\n",
    "\n",
    "plt.title(f'Many-to-Many Validation Forecasting: Actual vs {k} Prediction Steps')\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reshape cho inverse transform\n",
    "y_test_2d = y_test.reshape(-1, 1)\n",
    "preds_2d = preds.reshape(-1, 1)\n",
    "\n",
    "y_test_rescaled = scaler.inverse_transform(y_test_2d).reshape(y_test.shape)\n",
    "preds_rescaled = scaler.inverse_transform(preds_2d).reshape(preds.shape)\n",
    "\n",
    "# ----------------------------\n",
    "# Chuẩn bị actual price (trung bình nếu trùng)\n",
    "actual_dict = defaultdict(list)\n",
    "start_index = len(data) - len(y_test_rescaled) - best_params['window_size']\n",
    "\n",
    "for i in range(len(y_test_rescaled)):\n",
    "    start = start_index + i + best_params['window_size']\n",
    "    for j in range(y_test_rescaled.shape[1]):\n",
    "        date_idx = start + j\n",
    "        if date_idx < len(data):\n",
    "            date = data.index[date_idx]\n",
    "            actual_dict[date].append(y_test_rescaled[i][j])\n",
    "\n",
    "# Trung bình giá thực tế nếu trùng\n",
    "actual_dates = sorted(actual_dict.keys())\n",
    "actual_avg = np.array([np.mean(actual_dict[d]) for d in actual_dates])\n",
    "\n",
    "# ----------------------------\n",
    "# Dự đoán theo từng bước t+1, t+2, ..., t+k\n",
    "k = preds_rescaled.shape[1]\n",
    "pred_step_dict = [defaultdict(list) for _ in range(k)]\n",
    "\n",
    "for i in range(len(preds_rescaled)):\n",
    "    start = start_index + i + best_params['window_size']\n",
    "    for j in range(k):\n",
    "        date_idx = start + j\n",
    "        if date_idx < len(data):\n",
    "            date = data.index[date_idx]\n",
    "            pred_step_dict[j][date].append(preds_rescaled[i][j])\n",
    "\n",
    "# Trung bình từng bước + tính MAE\n",
    "pred_lines = []\n",
    "step_mae = []\n",
    "for j in range(k):\n",
    "    common_dates = sorted(set(pred_step_dict[j].keys()) & set(actual_dict.keys()))\n",
    "    pred_avg = np.array([np.mean(pred_step_dict[j][d]) for d in common_dates])\n",
    "    actual_avg_step = np.array([np.mean(actual_dict[d]) for d in common_dates])\n",
    "    pred_lines.append((common_dates, pred_avg))\n",
    "    step_mae.append(np.mean(np.abs(pred_avg - actual_avg_step)))\n",
    "\n",
    "# ----------------------------\n",
    "# Trung bình tất cả bước dự đoán\n",
    "combined_pred_dict = defaultdict(list)\n",
    "for j in range(k):\n",
    "    for date, values in pred_step_dict[j].items():\n",
    "        combined_pred_dict[date].extend(values)\n",
    "\n",
    "common_avg_dates = sorted(set(combined_pred_dict.keys()) & set(actual_dict.keys()))\n",
    "avg_pred_line = np.array([np.mean(combined_pred_dict[d]) for d in common_avg_dates])\n",
    "\n",
    "# ----------------------------\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Đường giá thực tế\n",
    "plt.plot(actual_dates, actual_avg, label='Actual Price', linewidth=2)\n",
    "\n",
    "# Các đường dự đoán t+1 đến t+k\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, k))\n",
    "for j in range(k):\n",
    "    dates, preds_j = pred_lines[j]\n",
    "    plt.plot(dates, preds_j, label=f'Predicted t+{j+1}', color=colors[j], alpha=0.7, linewidth=2)\n",
    "\n",
    "# Đường trung bình các bước dự đoán\n",
    "plt.plot(common_avg_dates, avg_pred_line, label='Average Prediction', color='black', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.title(f'Many-to-Many Forecasting: Actual vs {k} Prediction Steps')\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94e8be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính MAE và MAPE cho đường dự đoán trung bình\n",
    "common_actual_avg = np.array([np.mean(actual_dict[d]) for d in common_avg_dates])\n",
    "\n",
    "# MAE: sai số tuyệt đối trung bình\n",
    "avg_mae = np.mean(np.abs(avg_pred_line - common_actual_avg))\n",
    "\n",
    "# MAPE: sai số phần trăm tuyệt đối trung bình\n",
    "# Tránh chia cho 0 bằng cách thêm epsilon nhỏ\n",
    "epsilon = 1e-8\n",
    "avg_mape = np.mean(np.abs((common_actual_avg - avg_pred_line) / (common_actual_avg + epsilon))) * 100\n",
    "\n",
    "print(f\"\\n➡️  MAE (Average Prediction): {avg_mae:.4f} USD\")\n",
    "print(f\"➡️  MAPE (Average Prediction): {avg_mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc53b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# preds, y_test đã rescale rồi (preds_rescaled, y_test_rescaled)\n",
    "# Giả sử: preds_rescaled.shape = (num_samples, k)\n",
    "#         y_test_rescaled.shape = (num_samples, k)\n",
    "\n",
    "k = preds_rescaled.shape[1]\n",
    "step_wise_mae = []\n",
    "\n",
    "for step in range(k):\n",
    "    mae = mean_absolute_error(y_test_rescaled[:, step], preds_rescaled[:, step])\n",
    "    step_wise_mae.append(mae)\n",
    "\n",
    "# In ra từng step\n",
    "for i, mae in enumerate(step_wise_mae):\n",
    "    print(f\"Step t+{i+1}: MAE = {mae:.4f} dollars\")\n",
    "\n",
    "# Vẽ biểu đồ MAE theo từng bước\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, k + 1), step_wise_mae, marker='o')\n",
    "plt.title(\"Step-wise MAE of Predictions\")\n",
    "plt.xlabel(\"Prediction Step (t+1 to t+k)\")\n",
    "plt.ylabel(\"Mean Absolute Error (dollars)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
