{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0639c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # thư viện tính toán số học\n",
    "import pandas as pd # thư viện giúp đọc file và xử lí dữ liệu dạng bảng\n",
    "import yfinance as yf # thư viện lấy dữ liệu\n",
    "import tensorflow as tf # thư viện model\n",
    "from tensorflow.keras.models import Sequential # Sắp xếp các lớp\n",
    "from tensorflow.keras.layers import Layer, LSTM, Dense, Dropout # Các lớp sử dụng trong mô hình\n",
    "from sklearn.preprocessing import MinMaxScaler # Chuẩn hóa dữ liệu\n",
    "from sklearn.metrics import mean_squared_error # Tính độ lỗi\n",
    "import matplotlib.pyplot as plt # Thư viện vẽ đồ thị\n",
    "import random # random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba8d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải dữ liệu 10 năm dùng thư viện yfinance\n",
    "def download_stock_data(ticker):\n",
    "    data = yf.download(ticker, period=\"10y\", interval=\"1d\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9812d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ví dụ về 1 mã cổ phiếu\n",
    "data = download_stock_data(\"AAPL\")\n",
    "# Đảm bảo dữ liệu là của các ngày liên tục ('D': daily),\n",
    "# các ngày không có dữ liệu (T7,CN) thì giá trị dữ liệu được gán NaN\n",
    "data = data.asfreq('D')\n",
    "\n",
    "# Kiểm tra 10 dòng đầu để đảm bảo không sót ngày nào\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c4f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna() là hàm dùng để ghi đè các ô có giá trị NaN\n",
    "# method='ffill' (forward fill) nghĩa là: Nếu một ô có giá trị NaN,\n",
    "# hãy lấy giá trị ở dòng phía trên nó để điền vào ()\n",
    "data = data.fillna(method='ffill')\n",
    "\n",
    "# Kiểm tra 10 dòng đầu để đảm bảo không còn giá trị NaN nào.\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4020ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy ra duy nhất cột giá đóng cửa (Close) –\n",
    "# đây là dữ liệu quan trọng nhất trong phân tích tài chính và dự báo.\n",
    "close_prices = data[['Close']]\n",
    "\n",
    "# Kiểm tra 10 giá trị đầu của chuỗi Close, để đảm bảo dữ liệu được lọc đúng.\n",
    "close_prices.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a79962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vẽ đồ thị giá thực\n",
    "dates = data.index[:]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dates, close_prices, label='Actual Price')\n",
    "plt.title('Stock Price Actual')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120eacd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def directional_loss(y_true, y_pred):\n",
    "    diff_true = y_true[:, 1:] - y_true[:, :-1]\n",
    "    diff_pred = y_pred[:, 1:] - y_pred[:, :-1]\n",
    "    return tf.reduce_mean(tf.maximum(0.0, -diff_true * diff_pred))  # penalize opposite direction\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    alpha = 0.4\n",
    "    beta = 0.2  # phạt underprediction\n",
    "    gamma = 0.3  # phạt overprediction\n",
    "\n",
    "    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    dir_loss = directional_loss(y_true, y_pred)\n",
    "\n",
    "    under_penalty = tf.reduce_mean(tf.nn.relu(y_true - y_pred))\n",
    "    over_penalty = tf.reduce_mean(tf.nn.relu(y_pred - y_true))\n",
    "\n",
    "    return mse + alpha * dir_loss + beta * under_penalty + gamma * over_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b1ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.2: Build LSTM model using library\n",
    "def build_model(input_shape, units=50, output_steps=5):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(output_steps))  # Output shape = (batch_size, k)\n",
    "    model.compile(optimizer='adam', loss= combined_loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc50f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "def create_dataset(data, window_size=60, k=5):\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data) - k + 1):  # ensure enough room for k steps\n",
    "        X.append(data[i - window_size:i])\n",
    "        y.append(data[i:i + k].flatten())  # output is a sequence of k steps\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584ca71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy dữ liệu gốc\n",
    "close_prices = data['Close'].values.reshape(-1, 1)\n",
    "total_len = len(close_prices)\n",
    "\n",
    "# Chia theo 80% train, 10% val, 10% test\n",
    "train_end = int(0.8 * total_len)\n",
    "val_end = int(0.9 * total_len)\n",
    "\n",
    "# ⚠️ Giữ lại 90 ngày trước khi chia để đủ cho mọi window_size\n",
    "max_window_size = 180\n",
    "train_raw = close_prices[:train_end]\n",
    "val_raw = close_prices[train_end - max_window_size:val_end]\n",
    "test_raw = close_prices[val_end - max_window_size:]\n",
    "\n",
    "# Chuẩn hóa\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train_raw)\n",
    "val_scaled = scaler.transform(val_raw)\n",
    "test_scaled = scaler.transform(test_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2086f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def particle_swarm_optimization(population_size=20, max_generations=30,patience=5, target_mse=0.001, no_improve_count=0, w_max=0.9, w_min = 0.4, k=5):\n",
    "    # 1. Tạo cá thể ngẫu nhiên (tọa độ và vận tốc)\n",
    "    def create_particle():\n",
    "        position = {\n",
    "            'window_size': random.randint(30, 180),\n",
    "            'units': random.choice([64, 128])\n",
    "        }\n",
    "        velocity = {\n",
    "            'window_size': random.uniform(-10, 10),\n",
    "            'units': random.choice([-32, 0, 32])\n",
    "        }\n",
    "        return {\n",
    "            'position': position,\n",
    "            'velocity': velocity,\n",
    "            'best_position': position.copy(),\n",
    "            'best_score': float('inf')\n",
    "        }\n",
    "\n",
    "    # 2. Tính fitness\n",
    "    def fitness(ind):\n",
    "        window_size = int(round(ind['position']['window_size']))\n",
    "        units = int(ind['position']['units'])\n",
    "\n",
    "        # Giới hạn window_size nằm trong [30, 90] và units nằm trong {32, 64, 128}\n",
    "        window_size = min(90, max(30, window_size))\n",
    "        units = min([64, 128], key=lambda x: abs(x - units))\n",
    "\n",
    "        # Tạo dataset từ tập đã chia & chuẩn hóa\n",
    "        X_train, y_train = create_dataset(train_scaled, window_size, k)\n",
    "        X_val, y_val = create_dataset(val_scaled, window_size, k)\n",
    "\n",
    "        model = build_model((window_size, 1), units=units, output_steps=k)\n",
    "        model.fit(X_train, y_train, epochs=3, batch_size=32, verbose=0)\n",
    "        preds = model.predict(X_val)\n",
    "\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "        return mse, window_size, units\n",
    "\n",
    "\n",
    "    # 3. Khởi tạo quần thể\n",
    "    swarm = [create_particle() for _ in range(population_size)]\n",
    "    global_best_position = None\n",
    "    global_best_score = float('inf')\n",
    "    best_score_history = float('inf')\n",
    "\n",
    "    for gen in range(max_generations):\n",
    "        print(f\"\\nLoop {gen+1}\")\n",
    "        w = w_max - (w_max - w_min) * gen / max_generations\n",
    "        c1 = 2.5 - 2 * (gen / max_generations)\n",
    "        c2 = 0.5 + 2 * (gen / max_generations)\n",
    "        for i, particle in enumerate(swarm):\n",
    "            score, actual_ws, actual_units = fitness(particle)\n",
    "            print(f\"Particle {i+1}: window_size={actual_ws}, units={actual_units}, MSE={score:.6f}\")\n",
    "\n",
    "            if score < particle['best_score']:\n",
    "                particle['best_score'] = score\n",
    "                particle['best_position'] = particle['position'].copy()\n",
    "\n",
    "            if score < global_best_score:\n",
    "                global_best_score = score\n",
    "                global_best_position = particle['position'].copy()\n",
    "\n",
    "        # 4. Cập nhật vận tốc và vị trí\n",
    "        for particle in swarm:\n",
    "            for key in ['window_size', 'units']:\n",
    "                r1 = random.random()\n",
    "                r2 = random.random()\n",
    "                cognitive = c1 * r1 * (particle['best_position'][key] - particle['position'][key])\n",
    "                social = c2 * r2 * (global_best_position[key] - particle['position'][key])\n",
    "                particle['velocity'][key] = w * particle['velocity'][key] + cognitive + social\n",
    "                #particle['position'][key] += particle['velocity'][key]\n",
    "\n",
    "                # 👉 Velocity Clamping (Giới hạn vận tốc)\n",
    "                #v_max = {'window_size': 10, 'units': 32}\n",
    "                #particle['velocity'][key] = max(-v_max[key], min(v_max[key], particle['velocity'][key]))\n",
    "\n",
    "                particle['position'][key] += particle['velocity'][key]\n",
    "                # Giới hạn window_size và units\n",
    "                if key == 'window_size':\n",
    "                    particle['position'][key] = min(180, max(30, particle['position'][key]))\n",
    "                elif key == 'units':\n",
    "                    # Chỉ cho phép gần các giá trị 32, 64, 128\n",
    "                    raw_units = particle['position'][key]\n",
    "                    particle['position'][key] = min([64, 128], key=lambda x: abs(x - raw_units))\n",
    "                    \n",
    "        print(f\"Best individual of generation {gen+1}: window_size={int(global_best_position['window_size'])}, units={int(global_best_position['units'])}, MSE={global_best_score:.6f}\")\n",
    "\n",
    "         # 🔸 Điều kiện dừng sớm\n",
    "        if global_best_score < best_score_history:\n",
    "            best_score_history = global_best_score\n",
    "            no_improve_count = 0 #reset bộ đếm\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "\n",
    "        if global_best_score <= target_mse:\n",
    "            print(f\"Early stopping: đạt MSE mục tiêu {target_mse} ở thế hệ {gen+1}.\")\n",
    "            break\n",
    "        if no_improve_count >= patience:\n",
    "            print(f\"Early stopping: không cải thiện trong {patience} thế hệ.\")\n",
    "            break\n",
    "\n",
    "    # Trả về kết quả tốt nhất\n",
    "    final_window_size = int(round(global_best_position['window_size']))\n",
    "    final_units = int(global_best_position['units'])\n",
    "    print(f\"\\nFinal best individual: window_size={final_window_size}, units={final_units}, MSE={global_best_score:.6f}\")\n",
    "    return {'window_size': final_window_size, 'units': final_units}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e843eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # GA optimization\n",
    "best_params = particle_swarm_optimization(k=5)\n",
    "print(\"Best Parameters from PSO:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a630a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 1. Lấy dữ liệu gốc (chưa chuẩn hóa)\n",
    "close_prices = data['Close'].values.reshape(-1, 1)\n",
    "\n",
    "# 2. Chia dữ liệu theo tỉ lệ 80% train, 10% val, 10% test\n",
    "total_len = len(close_prices)\n",
    "train_end = int(total_len * 0.8)\n",
    "val_end = int(total_len * 0.9)\n",
    "\n",
    "train_prices = close_prices[:train_end]\n",
    "val_prices = close_prices[train_end - best_params['window_size']:val_end]\n",
    "test_prices = close_prices[val_end - best_params['window_size']:]  # giữ lại window_size ngày\n",
    "\n",
    "# 3. Fit scaler trên tập train và transform cả 3 phần\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train = scaler.fit_transform(train_prices)\n",
    "scaled_val = scaler.transform(val_prices)\n",
    "scaled_test = scaler.transform(test_prices)\n",
    "\n",
    "# 4. Tạo dataset\n",
    "k=5\n",
    "X_train, y_train = create_dataset(scaled_train, best_params['window_size'], k)\n",
    "X_val, y_val = create_dataset(scaled_val, best_params['window_size'], k)\n",
    "X_test, y_test = create_dataset(scaled_test, best_params['window_size'], k)\n",
    "\n",
    "# 5. Gộp train + val để train mô hình cuối cùng\n",
    "X_final_train = np.concatenate([X_train, X_val])\n",
    "y_final_train = np.concatenate([y_train, y_val])\n",
    "\n",
    "# 6. Xây mô hình\n",
    "model = build_model((best_params['window_size'], 1), best_params['units'])\n",
    "\n",
    "# 7. EarlyStopping (monitor trên `loss` vì không có val)\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 8. Huấn luyện trên train + val\n",
    "model.fit(\n",
    "    X_final_train, y_final_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# 9. Dự đoán trên test set và tính RMSE\n",
    "preds = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"✅ Test RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "val_preds = model.predict(X_val)\n",
    "\n",
    "def plot_all_forecasts(data, scaler, best_params, y_val, val_preds, y_test, test_preds):\n",
    "    window_size = best_params['window_size']\n",
    "    k = y_val.shape[1]\n",
    "\n",
    "    total_len = len(data)\n",
    "    train_end = int(0.8 * total_len)\n",
    "    val_end = int(0.9 * total_len)\n",
    "\n",
    "    # --- 1. Lấy index gốc ---\n",
    "    train_dates = data.index[:train_end]\n",
    "\n",
    "    val_start_index = train_end - window_size\n",
    "    test_start_index = val_end - window_size\n",
    "\n",
    "    # --- 2. Giải scale ---\n",
    "    y_val_rescaled = scaler.inverse_transform(y_val.reshape(-1, 1)).reshape(y_val.shape)\n",
    "    val_preds_rescaled = scaler.inverse_transform(val_preds.reshape(-1, 1)).reshape(val_preds.shape)\n",
    "\n",
    "    y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1)).reshape(y_test.shape)\n",
    "    test_preds_rescaled = scaler.inverse_transform(test_preds.reshape(-1, 1)).reshape(test_preds.shape)\n",
    "\n",
    "    # --- 3. Tạo dict giá thực ---\n",
    "    def get_actual_dict(y_rescaled, start_idx):\n",
    "        actual_dict = defaultdict(list)\n",
    "        for i in range(len(y_rescaled)):\n",
    "            start = start_idx + i + window_size\n",
    "            for j in range(y_rescaled.shape[1]):\n",
    "                date_idx = start + j\n",
    "                if date_idx < len(data):\n",
    "                    date = data.index[date_idx]\n",
    "                    actual_dict[date].append(y_rescaled[i][j])\n",
    "        return actual_dict\n",
    "\n",
    "    actual_val = get_actual_dict(y_val_rescaled, val_start_index)\n",
    "    actual_test = get_actual_dict(y_test_rescaled, test_start_index)\n",
    "\n",
    "    # --- 4. Dự đoán từng bước ---\n",
    "    def get_pred_lines(preds_rescaled, start_idx):\n",
    "        pred_step_dict = [defaultdict(list) for _ in range(k)]\n",
    "        for i in range(len(preds_rescaled)):\n",
    "            start = start_idx + i + window_size\n",
    "            for j in range(k):\n",
    "                date_idx = start + j\n",
    "                if date_idx < len(data):\n",
    "                    date = data.index[date_idx]\n",
    "                    pred_step_dict[j][date].append(preds_rescaled[i][j])\n",
    "        pred_lines = []\n",
    "        for j in range(k):\n",
    "            common_dates = sorted(set(pred_step_dict[j].keys()))\n",
    "            pred_avg = np.array([np.mean(pred_step_dict[j][d]) for d in common_dates])\n",
    "            pred_lines.append((common_dates, pred_avg))\n",
    "        return pred_lines\n",
    "\n",
    "    val_pred_lines = get_pred_lines(val_preds_rescaled, val_start_index)\n",
    "    test_pred_lines = get_pred_lines(test_preds_rescaled, test_start_index)\n",
    "\n",
    "    # --- 5. Plot ---\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    # Train thực tế\n",
    "    plt.plot(train_dates, data['Close'][:train_end], label='Train Actual', color='gray', linewidth=1.5)\n",
    "\n",
    "    # Val thực tế\n",
    "    val_actual_dates = sorted(actual_val.keys())\n",
    "    val_actual_avg = np.array([np.mean(actual_val[d]) for d in val_actual_dates])\n",
    "    plt.plot(val_actual_dates, val_actual_avg, label='Val Actual', color='blue', linewidth=2)\n",
    "\n",
    "    # Test thực tế\n",
    "    test_actual_dates = sorted(actual_test.keys())\n",
    "    test_actual_avg = np.array([np.mean(actual_test[d]) for d in test_actual_dates])\n",
    "    plt.plot(test_actual_dates, test_actual_avg, label='Test Actual', color='black', linewidth=2)\n",
    "\n",
    "    # Các bước dự đoán val\n",
    "    colors = plt.cm.Blues(np.linspace(0.4, 0.9, k))\n",
    "    for j, (dates, preds_j) in enumerate(val_pred_lines):\n",
    "        plt.plot(dates, preds_j, label=f'Val Predicted t+{j+1}', color=colors[j], linestyle='--')\n",
    "\n",
    "    # Các bước dự đoán test\n",
    "    colors = plt.cm.Greens(np.linspace(0.4, 0.9, k))\n",
    "    for j, (dates, preds_j) in enumerate(test_pred_lines):\n",
    "        plt.plot(dates, preds_j, label=f'Test Predicted t+{j+1}', color=colors[j], linestyle='--')\n",
    "\n",
    "    plt.title(f'Stock Forecasting: Actual vs {k}-step Predictions')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_all_forecasts(data, scaler, best_params, y_val, val_preds, y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625d5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập validation\n",
    "val_preds = model.predict(X_val)\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Rescale val ground truth và dự đoán\n",
    "y_val_2d = y_val.reshape(-1, 1)\n",
    "val_preds_2d = val_preds.reshape(-1, 1)\n",
    "\n",
    "y_val_rescaled = scaler.inverse_transform(y_val_2d).reshape(y_val.shape)\n",
    "val_preds_rescaled = scaler.inverse_transform(val_preds_2d).reshape(val_preds.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Tạo actual_dict từ y_val_rescaled\n",
    "actual_dict = defaultdict(list)\n",
    "val_start_index = len(data) - len(y_test) - len(y_val) - best_params['window_size']\n",
    "\n",
    "for i in range(len(y_val_rescaled)):\n",
    "    start = val_start_index + i + best_params['window_size']\n",
    "    for j in range(y_val_rescaled.shape[1]):\n",
    "        date_idx = start + j\n",
    "        if date_idx < len(data):\n",
    "            date = data.index[date_idx]\n",
    "            actual_dict[date].append(y_val_rescaled[i][j])\n",
    "\n",
    "actual_dates = sorted(actual_dict.keys())\n",
    "actual_avg = np.array([np.mean(actual_dict[d]) for d in actual_dates])\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Dự đoán từng bước t+1, ..., t+k\n",
    "k = val_preds_rescaled.shape[1]\n",
    "pred_step_dict = [defaultdict(list) for _ in range(k)]\n",
    "\n",
    "for i in range(len(val_preds_rescaled)):\n",
    "    start = val_start_index + i + best_params['window_size']\n",
    "    for j in range(k):\n",
    "        date_idx = start + j\n",
    "        if date_idx < len(data):\n",
    "            date = data.index[date_idx]\n",
    "            pred_step_dict[j][date].append(val_preds_rescaled[i][j])\n",
    "\n",
    "# Trung bình từng bước\n",
    "pred_lines = []\n",
    "step_mae = []\n",
    "for j in range(k):\n",
    "    common_dates = sorted(set(pred_step_dict[j].keys()) & set(actual_dict.keys()))\n",
    "    pred_avg = np.array([np.mean(pred_step_dict[j][d]) for d in common_dates])\n",
    "    actual_avg_step = np.array([np.mean(actual_dict[d]) for d in common_dates])\n",
    "    pred_lines.append((common_dates, pred_avg))\n",
    "    step_mae.append(np.mean(np.abs(pred_avg - actual_avg_step)))\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Đường thực tế\n",
    "plt.plot(actual_dates, actual_avg, label='Actual Price', color='black', linewidth=2)\n",
    "\n",
    "# Các đường dự đoán t+1 đến t+k\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, k))\n",
    "for j in range(k):\n",
    "    dates, preds_j = pred_lines[j]\n",
    "    plt.plot(dates, preds_j, label=f'Predicted t+{j+1}', color=colors[j], alpha=0.7)\n",
    "\n",
    "plt.title(f'Many-to-Many Validation Forecasting: Actual vs {k} Prediction Steps')\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4054c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#n ngày để dự đoán k ngày (n+1 được dự đoán bởi n ngày, n+2 được dự đoán bởi n ngày)\n",
    "#(window_size, units) -> hơi khó\n",
    "# Reshape cho inverse transform\n",
    "y_test_2d = y_test.reshape(-1, 1)\n",
    "preds_2d = preds.reshape(-1, 1)\n",
    "\n",
    "y_test_rescaled = scaler.inverse_transform(y_test_2d).reshape(y_test.shape)\n",
    "preds_rescaled = scaler.inverse_transform(preds_2d).reshape(preds.shape)\n",
    "\n",
    "# ----------------------------\n",
    "# Chuẩn bị actual price (trung bình nếu trùng)\n",
    "actual_dict = defaultdict(list)\n",
    "start_index = len(data) - len(y_test_rescaled) - best_params['window_size']\n",
    "\n",
    "for i in range(len(y_test_rescaled)):\n",
    "    start = start_index + i + best_params['window_size']\n",
    "    for j in range(y_test_rescaled.shape[1]):\n",
    "        date_idx = start + j\n",
    "        if date_idx < len(data):\n",
    "            date = data.index[date_idx]\n",
    "            actual_dict[date].append(y_test_rescaled[i][j])\n",
    "\n",
    "# Trung bình giá thực tế nếu trùng\n",
    "actual_dates = sorted(actual_dict.keys())\n",
    "actual_avg = np.array([np.mean(actual_dict[d]) for d in actual_dates])\n",
    "\n",
    "# ----------------------------\n",
    "# Dự đoán theo từng bước t+1, t+2, ..., t+k\n",
    "k = preds_rescaled.shape[1]\n",
    "pred_step_dict = [defaultdict(list) for _ in range(k)]\n",
    "\n",
    "for i in range(len(preds_rescaled)):\n",
    "    start = start_index + i + best_params['window_size']\n",
    "    for j in range(k):\n",
    "        date_idx = start + j\n",
    "        if date_idx < len(data):\n",
    "            date = data.index[date_idx]\n",
    "            pred_step_dict[j][date].append(preds_rescaled[i][j])\n",
    "\n",
    "# Trung bình từng bước + tính MAE\n",
    "pred_lines = []\n",
    "step_mae = []\n",
    "for j in range(k):\n",
    "    common_dates = sorted(set(pred_step_dict[j].keys()) & set(actual_dict.keys()))\n",
    "    pred_avg = np.array([np.mean(pred_step_dict[j][d]) for d in common_dates])\n",
    "    actual_avg_step = np.array([np.mean(actual_dict[d]) for d in common_dates])\n",
    "    pred_lines.append((common_dates, pred_avg))\n",
    "    step_mae.append(np.mean(np.abs(pred_avg - actual_avg_step)))\n",
    "\n",
    "# ----------------------------\n",
    "# Trung bình tất cả bước dự đoán\n",
    "combined_pred_dict = defaultdict(list)\n",
    "for j in range(k):\n",
    "    for date, values in pred_step_dict[j].items():\n",
    "        combined_pred_dict[date].extend(values)\n",
    "\n",
    "common_avg_dates = sorted(set(combined_pred_dict.keys()) & set(actual_dict.keys()))\n",
    "avg_pred_line = np.array([np.mean(combined_pred_dict[d]) for d in common_avg_dates])\n",
    "\n",
    "# ----------------------------\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Đường giá thực tế\n",
    "plt.plot(actual_dates, actual_avg, label='Actual Price', linewidth=2)\n",
    "\n",
    "# Các đường dự đoán t+1 đến t+k\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, k))\n",
    "for j in range(k):\n",
    "    dates, preds_j = pred_lines[j]\n",
    "    plt.plot(dates, preds_j, label=f'Predicted t+{j+1}', color=colors[j], alpha=0.7, linewidth=2)\n",
    "\n",
    "# Đường trung bình các bước dự đoán\n",
    "plt.plot(common_avg_dates, avg_pred_line, label='Average Prediction', color='black', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.title(f'Many-to-Many Forecasting: Actual vs {k} Prediction Steps')\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1502051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính MAE và MAPE cho đường dự đoán trung bình\n",
    "common_actual_avg = np.array([np.mean(actual_dict[d]) for d in common_avg_dates])\n",
    "\n",
    "# MAE: sai số tuyệt đối trung bình\n",
    "avg_mae = np.mean(np.abs(avg_pred_line - common_actual_avg))\n",
    "\n",
    "# MAPE: sai số phần trăm tuyệt đối trung bình\n",
    "# Tránh chia cho 0 bằng cách thêm epsilon nhỏ\n",
    "epsilon = 1e-8\n",
    "avg_mape = np.mean(np.abs((common_actual_avg - avg_pred_line) / (common_actual_avg + epsilon))) * 100\n",
    "\n",
    "print(f\"\\n➡️  MAE (Average Prediction): {avg_mae:.4f} USD\")\n",
    "print(f\"➡️  MAPE (Average Prediction): {avg_mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# preds, y_test đã rescale rồi (preds_rescaled, y_test_rescaled)\n",
    "# Giả sử: preds_rescaled.shape = (num_samples, k)\n",
    "#         y_test_rescaled.shape = (num_samples, k)\n",
    "\n",
    "k = preds_rescaled.shape[1]\n",
    "step_wise_mae = []\n",
    "\n",
    "for step in range(k):\n",
    "    mae = mean_absolute_error(y_test_rescaled[:, step], preds_rescaled[:, step])\n",
    "    step_wise_mae.append(mae)\n",
    "\n",
    "# In ra từng step\n",
    "for i, mae in enumerate(step_wise_mae):\n",
    "    print(f\"Step t+{i+1}: MAE = {mae:.4f} dollars\")\n",
    "\n",
    "# Vẽ biểu đồ MAE theo từng bước\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, k + 1), step_wise_mae, marker='o')\n",
    "plt.title(\"Step-wise MAE of Predictions\")\n",
    "plt.xlabel(\"Prediction Step (t+1 to t+k)\")\n",
    "plt.ylabel(\"Mean Absolute Error (dollars)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
